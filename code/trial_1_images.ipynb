{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for code: https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n",
    "\n",
    "# Specify the paths for the 2 files\n",
    "protoFile = \"pose_deploy.prototxt\"\n",
    "weightsFile = \"pose_iter_584000.caffemodel\"\n",
    "\n",
    "# Read the network into Memory\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_skeleton(frame):\n",
    "\n",
    "    frame_copy = np.copy(frame)\n",
    "\n",
    "    # Specify the input image dimensions\n",
    "    inWidth = 368\n",
    "    inHeight = 368\n",
    "\n",
    "    # Prepare the frame to be fed to the network\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame_copy, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # Set the prepared object as the input blob of the network\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    output = net.forward()\n",
    "\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "    for i in range(15):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frame_copy.shape[1] * point[0]) / W\n",
    "        y = (frame_copy.shape[0] * point[1]) / H\n",
    "\n",
    "        if prob > 0.5:\n",
    "            cv2.circle(frame_copy, (int(x), int(y)), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame_copy, f\"{i}\", (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "        else:\n",
    "            points.append(None)\n",
    "    \n",
    "    return frame_copy, points\n",
    "\n",
    "    # cv2.imshow(\"Output-Keypoints\",frame)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the image filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_image.jpg\", OUTPUT filepath will be \"my_folder1/my_folder2/my_image_WITH_AGE.jpg\"\n",
    "\n",
    "def new_img_name(org_img_path):\n",
    "    img_path, img_name_ext = os.path.split(org_img_path)\n",
    "    img_name, img_ext = os.path.splitext(img_name_ext)\n",
    "\n",
    "    new_img_name_ext = img_name+\"_WITH_POINTS\"+img_ext\n",
    "    new_img_path = os.path.join(img_path, new_img_name_ext)\n",
    "\n",
    "    return new_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the image filepath as a string below.\n",
    "# For example: \"my_image.jpg\" or \"/content/drive/My Drive/my_folder/my_image.png\"\n",
    "\n",
    "my_image = \"single.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to single_WITH_POINTS.png\n"
     ]
    }
   ],
   "source": [
    "# Reading the image from filepath provided above and passing it through the age clasification method defined above.\n",
    "\n",
    "frame = cv2.imread(my_image)\n",
    "skeleton_frame, skeleton_frame_points = find_skeleton(frame)\n",
    "\n",
    "# Saving the new generated image with a new name at the same location. \n",
    "try:\n",
    "    new_my_image = new_img_name(my_image)\n",
    "    cv2.imwrite(new_my_image, skeleton_frame)\n",
    "    print(f\"Saved to {new_my_image}\")\n",
    "except:\n",
    "    print(\"Error: Could not save image!\")\n",
    "\n",
    "cv2.imshow(\"Skeleton Image\", skeleton_frame)\n",
    "cv2.waitKey(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(199, 122),\n",
       " (191, 155),\n",
       " (168, 133),\n",
       " (168, 89),\n",
       " (161, 55),\n",
       " (207, 166),\n",
       " (207, 200),\n",
       " (214, 222),\n",
       " (176, 222),\n",
       " (161, 222),\n",
       " (176, 278),\n",
       " (191, 333),\n",
       " (191, 233),\n",
       " (214, 289),\n",
       " (230, 345)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeleton_frame_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 353, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the video filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n",
    "\n",
    "def new_vid_name(org_vid_path):\n",
    "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
    "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "\n",
    "    new_vid_name_ext = vid_name+\"_WITH_POINTS\"+\".mp4\"\n",
    "    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n",
    "\n",
    "    return new_vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the video filepath as a string below\n",
    "# For example: \"my_video.mp4\" or \"/content/drive/My Drive/my_folder/my_video.mp4\"\n",
    "\n",
    "my_video = \"vertical_jump_side.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n",
    "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "# Creating a VideoCapture object.\n",
    "cap = cv2.VideoCapture(my_video)\n",
    "\n",
    "# Checking if video can be accessed successfully.\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read video!\")\n",
    "\n",
    "# Getting the video frame width and height.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Defining the codec and creating a VideoWriter object to save the output video at the same location.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "new_my_video = new_vid_name(my_video)\n",
    "out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n",
    "\n",
    "# Defining a new dataframe to store the skeleton point coordinates from each frame of the video.\n",
    "video_points_df = pd.DataFrame(columns=list(range(1,26)))\n",
    "frame_counter = 1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Grabbing each individual frame, frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        # Running human skeleton points detection on the grabbed frame.\n",
    "        skeleton_frame, skeleton_frame_points = find_skeleton(frame)\n",
    "        \n",
    "        # Saving frame to output video using the VideoWriter object defined above.\n",
    "        out.write(skeleton_frame)\n",
    "        \n",
    "        # Displaying the frame with age detected.\n",
    "        cv2.imshow(\"Output Video\", skeleton_frame)\n",
    "        \n",
    "        # Saving frame output skeleton point coordinates as a new row in above defined dataframe.\n",
    "        video_points_df[frame_counter] = skeleton_frame_points\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the VideoCapture and VideoWriter objects, and closing the displayed frame.\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Saved to {new_my_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = \"sample_resized_10.jpg\"\n",
    "\n",
    "# Read image\n",
    "frame = cv2.imread(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list(range(1,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
