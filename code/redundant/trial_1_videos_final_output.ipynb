{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for code: https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n",
    "\n",
    "# Specify the paths for the 2 files\n",
    "protoFile = \"../inputs_outputs/models/pose_deploy.prototxt\"\n",
    "weightsFile = \"../inputs_outputs/models/pose_iter_584000.caffemodel\"\n",
    "\n",
    "# Read the network into Memory\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vjump_criteria_df = pd.read_csv(\"../inputs_outputs/models/vjump_criteria.csv\")\n",
    "vjump_criteria_df[\"condition\"].fillna(value=\"\", inplace=True)\n",
    "# vjump_criteria_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide the video filepath as a string.\n",
      "\n",
      "../inputs_outputs/videos/vertical_jump_side_trial_1.mp4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Provide the video filepath as a string below\n",
    "# For example: \"my_video.mp4\" or \"/content/drive/My Drive/my_folder/my_video.mp4\"\n",
    "\n",
    "my_video = input(\"Provide the video filepath as a string.\\n\\nINPUT-> \")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the person in the video facing towards left or right of the video frame?\n",
      "\n",
      "INPUT-> left\n",
      "\n",
      "PROCESSING... PLEASE WAIT!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orient = input(\"Is the person in the video facing towards left or right of the video frame?\\n\\nINPUT-> \")\n",
    "orient = orient.lower()\n",
    "\n",
    "print(\"\\nPROCESSING... PLEASE WAIT!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n",
    "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "# Creating a VideoCapture object.\n",
    "cap = cv2.VideoCapture(my_video)\n",
    "\n",
    "# Checking if video can be accessed successfully.\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read video!\")\n",
    "\n",
    "total_frames = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Grabbing each individual frame, frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        total_frames += 1\n",
    "        \n",
    "        # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the VideoCapture object.\n",
    "cap.release()\n",
    "\n",
    "# print(total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_skeleton(frame, frame_counter):\n",
    "\n",
    "    frame_copy = np.copy(frame)\n",
    "\n",
    "    # Specify the input image dimensions\n",
    "    inWidth = 368\n",
    "    inHeight = 368\n",
    "\n",
    "    # Prepare the frame to be fed to the network\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame_copy, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # Set the prepared object as the input blob of the network\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    output = net.forward()\n",
    "\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "    for i in range(15):\n",
    "        # Confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frame_copy.shape[1] * point[0]) / W\n",
    "        y = (frame_copy.shape[0] * point[1]) / H\n",
    "\n",
    "        if prob > 0.5:\n",
    "            cv2.circle(frame_copy, (int(x), int(y)), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame_copy, f\"{i}\", (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            cv2.putText(frame_copy, f\"frame = {frame_counter}\", (10, frame_height-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "        else:\n",
    "            points.append(None)\n",
    "    \n",
    "    return frame_copy, points\n",
    "\n",
    "    # cv2.imshow(\"Output-Keypoints\",frame)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the video filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n",
    "\n",
    "def new_vid_name(org_vid_path):\n",
    "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
    "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "\n",
    "    new_vid_name_ext = vid_name+\"_WITH_BODY_POINTS\"+\".mp4\"\n",
    "    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n",
    "\n",
    "    return new_vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing video - frame 1 of 67...\n",
      "Analysing video - frame 2 of 67...\n",
      "Analysing video - frame 3 of 67...\n",
      "Analysing video - frame 4 of 67...\n",
      "Analysing video - frame 5 of 67...\n",
      "Analysing video - frame 6 of 67...\n",
      "Analysing video - frame 7 of 67...\n",
      "Analysing video - frame 8 of 67...\n",
      "Analysing video - frame 9 of 67...\n",
      "Analysing video - frame 10 of 67...\n",
      "Analysing video - frame 11 of 67...\n",
      "Analysing video - frame 12 of 67...\n",
      "Analysing video - frame 13 of 67...\n",
      "Analysing video - frame 14 of 67...\n",
      "Analysing video - frame 15 of 67...\n",
      "Analysing video - frame 16 of 67...\n",
      "Analysing video - frame 17 of 67...\n",
      "Analysing video - frame 18 of 67...\n",
      "Analysing video - frame 19 of 67...\n",
      "Analysing video - frame 20 of 67...\n",
      "Analysing video - frame 21 of 67...\n",
      "Analysing video - frame 22 of 67...\n",
      "Analysing video - frame 23 of 67...\n",
      "Analysing video - frame 24 of 67...\n",
      "Analysing video - frame 25 of 67...\n",
      "Analysing video - frame 26 of 67...\n",
      "Analysing video - frame 27 of 67...\n",
      "Analysing video - frame 28 of 67...\n",
      "Analysing video - frame 29 of 67...\n",
      "Analysing video - frame 30 of 67...\n",
      "Analysing video - frame 31 of 67...\n",
      "Analysing video - frame 32 of 67...\n",
      "Analysing video - frame 33 of 67...\n",
      "Analysing video - frame 34 of 67...\n",
      "Analysing video - frame 35 of 67...\n",
      "Analysing video - frame 36 of 67...\n",
      "Analysing video - frame 37 of 67...\n",
      "Analysing video - frame 38 of 67...\n",
      "Analysing video - frame 39 of 67...\n",
      "Analysing video - frame 40 of 67...\n",
      "Analysing video - frame 41 of 67...\n",
      "Analysing video - frame 42 of 67...\n",
      "Analysing video - frame 43 of 67...\n",
      "Analysing video - frame 44 of 67...\n",
      "Analysing video - frame 45 of 67...\n",
      "Analysing video - frame 46 of 67...\n",
      "Analysing video - frame 47 of 67...\n",
      "Analysing video - frame 48 of 67...\n",
      "Analysing video - frame 49 of 67...\n",
      "Analysing video - frame 50 of 67...\n",
      "Analysing video - frame 51 of 67...\n",
      "Analysing video - frame 52 of 67...\n",
      "Analysing video - frame 53 of 67...\n",
      "Analysing video - frame 54 of 67...\n",
      "Analysing video - frame 55 of 67...\n",
      "Analysing video - frame 56 of 67...\n",
      "Analysing video - frame 57 of 67...\n",
      "Analysing video - frame 58 of 67...\n",
      "Analysing video - frame 59 of 67...\n",
      "Analysing video - frame 60 of 67...\n",
      "Analysing video - frame 61 of 67...\n",
      "Analysing video - frame 62 of 67...\n",
      "Analysing video - frame 63 of 67...\n",
      "Analysing video - frame 64 of 67...\n",
      "Analysing video - frame 65 of 67...\n",
      "Analysing video - frame 66 of 67...\n",
      "Analysing video - frame 67 of 67...\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n",
    "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "# Creating a VideoCapture object.\n",
    "cap = cv2.VideoCapture(my_video)\n",
    "\n",
    "# Checking if video can be accessed successfully.\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read video!\")\n",
    "\n",
    "# Getting the video frame width and height.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Defining the codec and creating a VideoWriter object to save the output video at the same location.\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "# new_my_video = new_vid_name(my_video)\n",
    "# out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n",
    "\n",
    "# Defining a new dataframe to store the skeleton point coordinates from each frame of the video.\n",
    "video_points_df = pd.DataFrame(columns=list(range(1,26)))\n",
    "frame_counter = 1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Grabbing each individual frame, frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        print(f\"Analysing video - frame {frame_counter} of {total_frames}...\")\n",
    "        \n",
    "        # Running human skeleton points detection on the grabbed frame.\n",
    "        skeleton_frame, skeleton_frame_points = find_skeleton(frame, frame_counter)\n",
    "        \n",
    "        # Saving frame to output video using the VideoWriter object defined above.\n",
    "        # out.write(skeleton_frame)\n",
    "        \n",
    "        # Displaying the frame with age detected.\n",
    "        # cv2.imshow(\"Output Video\", skeleton_frame)\n",
    "        \n",
    "        # Saving frame output skeleton point coordinates as a new row in above defined dataframe.\n",
    "        video_points_df[frame_counter] = skeleton_frame_points\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the VideoCapture and VideoWriter objects, and closing the displayed frame.\n",
    "cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()\n",
    "# print(f\"Saved to {new_my_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = video_points_df.T.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_width, frame_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vjump_points = [0, 1, 8]\n",
    "\n",
    "if orient == \"left\":\n",
    "    vjump_points.extend([5, 6, 7, 12, 13, 14])\n",
    "elif orient == \"right\":\n",
    "    vjump_points.extend([2, 3, 4, 9, 10, 11])\n",
    "\n",
    "# sorted(vjump_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df[vjump_points].copy()\n",
    "# df_imputed.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_break_in_series(points_series, start_i):\n",
    "    \n",
    "    break_start_i = start_i - 1\n",
    "    break_end_i = start_i\n",
    "    break_found = False\n",
    "    continue_crawling = True\n",
    "    \n",
    "    while (continue_crawling == True) and (break_end_i < points_series.index[-1]):\n",
    "    \n",
    "        if points_series[break_end_i] != None:\n",
    "            break_found = False\n",
    "            break_start_i = break_end_i\n",
    "            break_end_i += 1\n",
    "            \n",
    "        else:\n",
    "            break_found = True\n",
    "            # break_end_i += 1\n",
    "            \n",
    "            while (break_found == True) and (break_end_i <= points_series.index[-1]):\n",
    "                \n",
    "                if points_series[break_end_i] == None:\n",
    "                    break_end_i += 1\n",
    "                else:\n",
    "                    break_found = False\n",
    "                    \n",
    "            continue_crawling = False\n",
    "        \n",
    "    return break_start_i, break_end_i\n",
    "\n",
    "def impute_break_in_series(points_series, start_i, end_i):\n",
    "    \n",
    "    diff = end_i - start_i\n",
    "    start_x, start_y = points_series[start_i]\n",
    "    end_x, end_y = points_series[end_i]\n",
    "    \n",
    "    diff_x = (end_x - start_x) / diff\n",
    "    diff_y = (end_y - start_y) / diff\n",
    "    \n",
    "    multiplier = 1\n",
    "    \n",
    "    for i in range(start_i+1, end_i):\n",
    "        x = int(round(start_x + (diff_x * multiplier)))\n",
    "        y = int(round(start_y + (diff_y * multiplier)))\n",
    "        points_series[i] = (x, y)\n",
    "        multiplier += 1\n",
    "\n",
    "def imputing_missing_points_in_series(points_series):\n",
    "    \n",
    "    series_start_i = points_series.index[0]\n",
    "    series_end_i = points_series.index[-1]\n",
    "    \n",
    "    current_i = series_start_i\n",
    "    \n",
    "    while current_i < series_end_i:\n",
    "        \n",
    "        if points_series[current_i] == None:\n",
    "            current_i += 1\n",
    "            \n",
    "        else:\n",
    "            break_start_i, break_end_i = find_break_in_series(points_series, current_i)\n",
    "            \n",
    "            if break_end_i - break_start_i == 1:\n",
    "                break\n",
    "            elif break_end_i > series_end_i:\n",
    "                break\n",
    "            else: \n",
    "                impute_break_in_series(points_series, break_start_i, break_end_i)\n",
    "                current_i = break_end_i\n",
    "    \n",
    "    return points_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing analysis - data imputation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Continuing analysis - data imputation...\\n\")\n",
    "\n",
    "for i in vjump_points:\n",
    "    df_imputed[i] = imputing_missing_points(df_imputed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_imputed_skeleton(frame, points_row_imputed, points_row_original, frame_counter):\n",
    "\n",
    "    frame_copy = np.copy(frame)\n",
    "\n",
    "    for i in points_row_imputed.index:\n",
    "        \n",
    "        if points_row_imputed[i] != None:\n",
    "            \n",
    "            if points_row_original[i] != None:\n",
    "        \n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "                cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "                cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "                \n",
    "        cv2.putText(frame_copy, f\"frame = {frame_counter}\", (10, frame_height-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "                \n",
    "    return frame_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Points Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_norm = df_imputed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed_norm.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_upper_body_length():\n",
    "    \n",
    "    upper_body_length = 0\n",
    "    \n",
    "    for i in df.index:\n",
    "        \n",
    "        if ((df.loc[i, 1] != None) and (df.loc[i, 8] != None)):\n",
    "            \n",
    "            upper_chest_x, upper_chest_y = df.loc[i, 1]\n",
    "            navel_x, navel_y = df.loc[i, 8]\n",
    "            \n",
    "            upper_body_length = int(round(np.sqrt((upper_chest_x - navel_x)**2 + (upper_chest_y - navel_y)**2)))\n",
    "            \n",
    "            break\n",
    "            \n",
    "    # print(upper_body_length)\n",
    "    return upper_body_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing_body_points(row):\n",
    "    \n",
    "    # max_body_dim_x, max_body_dim_y = find_max_body_dimensions()\n",
    "    upper_body_length = find_upper_body_length()\n",
    "    \n",
    "    if row[origin_point] == None:\n",
    "        return row\n",
    "    \n",
    "    origin_x, origin_y = row[origin_point]\n",
    "    \n",
    "    for i in row.index:\n",
    "        \n",
    "        if i == origin_point:\n",
    "            norm_x = 0.0\n",
    "            norm_y = 0.0\n",
    "            row[i] = (norm_x, norm_y)\n",
    "            \n",
    "        elif row[i] == None:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            i_x, i_y = row[i]\n",
    "            norm_x = (i_x - origin_x) / (upper_body_length * 3)\n",
    "            norm_y = (i_y - origin_y) / (upper_body_length * 3)\n",
    "            norm_y = -1 * norm_y\n",
    "            row[i] = (norm_x, norm_y)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing analysis - data normalization...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Continuing analysis - data normalization...\\n\")\n",
    "\n",
    "for i in df_imputed_norm.index:\n",
    "    df_imputed_norm.loc[i] = normalizing_body_points(df_imputed_norm.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed_norm.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed_norm.tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Rules for Grading Vertical Jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing analysis - identifying critical frames...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tracking body point 0 in Y-axis to get frame number of peak in vertical jump.\n",
    "\n",
    "print(\"Continuing analysis - identifying critical frames...\\n\")\n",
    "\n",
    "forehead_y_movement = [frame_height - x[1] for x in df_imputed[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_peak_indexes = []\n",
    "\n",
    "for i, y in enumerate(forehead_y_movement):\n",
    "    if y == max(forehead_y_movement):\n",
    "        jump_peak_indexes.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_peak_frame = int(np.median(jump_peak_indexes))\n",
    "# jump_peak_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_squat_indexes = []\n",
    "\n",
    "for i, y in enumerate(forehead_y_movement[:jump_peak_frame]):\n",
    "    if y == min(forehead_y_movement[:jump_peak_frame]):\n",
    "        jump_squat_indexes.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_squat_frame = int(np.median(jump_squat_indexes))\n",
    "# jump_squat_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_land_indexes = []\n",
    "\n",
    "for i, y in enumerate(forehead_y_movement[jump_peak_frame:]):\n",
    "    if y == min(forehead_y_movement[jump_peak_frame:]):\n",
    "        jump_land_indexes.append(i+1+jump_peak_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_land_frame = int(np.median(jump_land_indexes))\n",
    "# jump_land_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_between_three_points(point_1, point_2, point_3):\n",
    "    \n",
    "    x_1, y_1 = point_1\n",
    "    x_2, y_2 = point_2\n",
    "    x_3, y_3 = point_3\n",
    "    \n",
    "    side_1_2 = np.sqrt((x_2 - x_1)**2 + (y_2 - y_1)**2)\n",
    "    side_2_3 = np.sqrt((x_3 - x_2)**2 + (y_3 - y_2)**2)\n",
    "    side_3_1 = np.sqrt((x_1 - x_3)**2 + (y_1 - y_3)**2)\n",
    "    \n",
    "    cos_theta_rad = ((side_1_2**2 + side_2_3**2 - side_3_1**2) / (2 * side_1_2 * side_2_3))\n",
    "    \n",
    "    theta_rad = np.arccos(cos_theta_rad)\n",
    "    \n",
    "    theta_deg = np.rad2deg(theta_rad)\n",
    "    \n",
    "    return theta_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_quality_at_squat_frame(frame, points_row_original, points_row_imputed, points_row_norm):\n",
    "    \n",
    "    frame_copy = np.copy(frame)\n",
    "    \n",
    "    temp_arm_points = []\n",
    "    temp_leg_points = []\n",
    "    temp_torso_points = []\n",
    "    \n",
    "    if orient == \"left\":\n",
    "        temp_arm_points = [5, 6, 7]\n",
    "        temp_leg_points = [12, 13, 14]\n",
    "        temp_torso_points = [5, 12]\n",
    "    elif orient == \"right\":\n",
    "        temp_arm_points = [2, 3, 4]\n",
    "        temp_leg_points = [9, 10, 11]\n",
    "        temp_torso_points = [2, 9]\n",
    "        \n",
    "    elbow_angle = calculate_angle_between_three_points(points_row_norm[temp_arm_points[0]],\n",
    "                                                       points_row_norm[temp_arm_points[1]],\n",
    "                                                       points_row_norm[temp_arm_points[2]]\n",
    "                                                      )\n",
    "    \n",
    "    knee_angle = calculate_angle_between_three_points(points_row_norm[temp_leg_points[0]],\n",
    "                                                      points_row_norm[temp_leg_points[1]],\n",
    "                                                      points_row_norm[temp_leg_points[2]]\n",
    "                                                     )\n",
    "    \n",
    "    shoulder_angle = calculate_angle_between_three_points(points_row_norm[temp_arm_points[1]],\n",
    "                                                          points_row_norm[temp_arm_points[0]],\n",
    "                                                          points_row_norm[temp_torso_points[1]]\n",
    "                                                         )\n",
    "    \n",
    "    hip_angle = calculate_angle_between_three_points(points_row_norm[temp_torso_points[0]],\n",
    "                                                     points_row_norm[temp_torso_points[1]],\n",
    "                                                     points_row_norm[temp_leg_points[1]]\n",
    "                                                    )\n",
    "    \n",
    "    correct_squat_posture = False\n",
    "    elbow_angle_pass = False\n",
    "    knee_angle_pass = False\n",
    "    shoulder_angle_pass = False\n",
    "    hip_angle_pass = False\n",
    "    \n",
    "    for i, p in enumerate(temp_arm_points[:-1]):\n",
    "        if elbow_angle > 160:\n",
    "            elbow_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_arm_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_arm_points[i+1]], (0, 0, 255), thickness=2)\n",
    "    \n",
    "    for i, p in enumerate(temp_leg_points[:-1]):\n",
    "        if 75 < knee_angle < 105:\n",
    "            knee_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_leg_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_leg_points[i+1]], (0, 0, 255), thickness=2)\n",
    "            \n",
    "    for i in points_row_imputed.index:\n",
    "        if points_row_imputed[i] != None:\n",
    "            if points_row_original[i] != None:\n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "                # cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "                # cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(frame_copy, f\"frame = {frame_counter}\", (10, frame_height-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    if elbow_angle_pass and knee_angle_pass:\n",
    "        correct_squat_posture = True\n",
    "    \n",
    "    frame_text = \"\"\n",
    "    if correct_squat_posture:\n",
    "        frame_text = \"Squat posture : PASS\"\n",
    "    else:\n",
    "        frame_text = \"Squat posture : FAIL\"\n",
    "    \n",
    "    report_text = f'''\n",
    "    {frame_text} (frame {frame_counter} of {total_frames})\n",
    "    Body angles:\n",
    "    \\tElbow:\\t{round(elbow_angle, 2)} deg\\t[correct range: >160 deg]\n",
    "    \\tKnee:\\t{round(knee_angle, 2)} deg\\t[correct range: 75-105 deg]\n",
    "    \\tShldr:\\t{round(shoulder_angle, 2)} deg\n",
    "    \\tHip:\\t{round(knee_angle, 2)} deg\n",
    "    '''\n",
    "\n",
    "    return frame_copy, frame_text, report_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_quality_at_peak_frame(frame, points_row_original, points_row_imputed, points_row_norm):\n",
    "    \n",
    "    frame_copy = np.copy(frame)\n",
    "    \n",
    "    temp_arm_points = []\n",
    "    temp_leg_points = []\n",
    "    temp_torso_points = []\n",
    "    \n",
    "    if orient == \"left\":\n",
    "        temp_arm_points = [5, 6, 7]\n",
    "        temp_leg_points = [12, 13, 14]\n",
    "        temp_torso_points = [5, 12]\n",
    "    elif orient == \"right\":\n",
    "        temp_arm_points = [2, 3, 4]\n",
    "        temp_leg_points = [9, 10, 11]\n",
    "        temp_torso_points = [2, 9]\n",
    "        \n",
    "    elbow_angle = calculate_angle_between_three_points(points_row_norm[temp_arm_points[0]],\n",
    "                                                       points_row_norm[temp_arm_points[1]],\n",
    "                                                       points_row_norm[temp_arm_points[2]]\n",
    "                                                      )\n",
    "    \n",
    "    knee_angle = calculate_angle_between_three_points(points_row_norm[temp_leg_points[0]],\n",
    "                                                      points_row_norm[temp_leg_points[1]],\n",
    "                                                      points_row_norm[temp_leg_points[2]]\n",
    "                                                      )\n",
    "    \n",
    "    torso_angle = calculate_angle_between_three_points((points_row_norm[temp_torso_points[0]][0], points_row_norm[temp_torso_points[0]][1] - 1), \n",
    "                                                       points_row_norm[temp_torso_points[0]],\n",
    "                                                       points_row_norm[temp_torso_points[1]]\n",
    "                                                      )\n",
    "    \n",
    "    correct_peak_posture = False\n",
    "    elbow_angle_pass = False\n",
    "    knee_angle_pass = False\n",
    "    torso_angle_pass = False\n",
    "    \n",
    "    for i, p in enumerate(temp_arm_points[:-1]):\n",
    "        if elbow_angle > 150:\n",
    "            elbow_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_arm_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_arm_points[i+1]], (0, 0, 255), thickness=2)\n",
    "    \n",
    "    for i, p in enumerate(temp_leg_points[:-1]):\n",
    "        if knee_angle > 150:\n",
    "            knee_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_leg_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_leg_points[i+1]], (0, 0, 255), thickness=2)\n",
    "            \n",
    "    for i, p in enumerate(temp_torso_points[:-1]):\n",
    "        if torso_angle < 20:\n",
    "            torso_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_torso_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_torso_points[i+1]], (0, 0, 255), thickness=2)\n",
    "    \n",
    "    for i in points_row_imputed.index:\n",
    "        if points_row_imputed[i] != None:\n",
    "            if points_row_original[i] != None:\n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "                # cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "                # cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(frame_copy, f\"frame = {frame_counter}\", (10, frame_height-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    if elbow_angle_pass and knee_angle_pass and torso_angle_pass:\n",
    "        correct_peak_posture = True\n",
    "    \n",
    "    frame_text = \"\"\n",
    "    if correct_peak_posture:\n",
    "        frame_text = \"Jump Peak posture : PASS\"\n",
    "    else:\n",
    "        frame_text = \"Jump Peak posture : FAIL\"\n",
    "    \n",
    "    report_text = f'''\n",
    "    {frame_text} (frame {frame_counter} of {total_frames})\n",
    "    Body angles:\n",
    "    \\tElbow:\\t{round(elbow_angle, 2)} deg\\t[correct range: >150 deg]\n",
    "    \\tKnee:\\t{round(knee_angle, 2)} deg\\t[correct range: >150 deg]\n",
    "    \\tTorso:\\t{round(torso_angle, 2)} deg\\t[correct range: <20 deg]\n",
    "    '''\n",
    "\n",
    "    return frame_copy, frame_text, report_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_from_squat_to_land():\n",
    "    \n",
    "    upper_body_length = find_upper_body_length()\n",
    "    \n",
    "    ankle_point = 0\n",
    "    \n",
    "    if orient == \"left\":\n",
    "        ankle_point = 14\n",
    "    elif orient == \"right\":\n",
    "        ankle_point = 11\n",
    "        \n",
    "    squat_ankle_x, squat_ankle_y = df_imputed.loc[jump_squat_frame, ankle_point]\n",
    "    land_ankle_x, land_ankle_y = df_imputed.loc[jump_land_frame, ankle_point]\n",
    "    \n",
    "    landing_distance = np.sqrt((land_ankle_x - squat_ankle_x)**2 + (land_ankle_y - squat_ankle_y)**2)\n",
    "    \n",
    "    return landing_distance / upper_body_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_quality_at_land_frame(frame, points_row_original, points_row_imputed, points_row_norm):\n",
    "    \n",
    "    frame_copy = np.copy(frame)\n",
    "    \n",
    "    temp_arm_points = []\n",
    "    temp_leg_points = []\n",
    "    temp_torso_points = []\n",
    "    \n",
    "    if orient == \"left\":\n",
    "        temp_arm_points = [5, 6, 7]\n",
    "        temp_leg_points = [12, 13, 14]\n",
    "        temp_torso_points = [5, 12]\n",
    "    elif orient == \"right\":\n",
    "        temp_arm_points = [2, 3, 4]\n",
    "        temp_leg_points = [9, 10, 11]\n",
    "        temp_torso_points = [2, 9]\n",
    "    \n",
    "    knee_angle = calculate_angle_between_three_points(points_row_norm[temp_leg_points[0]],\n",
    "                                                      points_row_norm[temp_leg_points[1]],\n",
    "                                                      points_row_norm[temp_leg_points[2]]\n",
    "                                                     )\n",
    "    \n",
    "    torso_angle = calculate_angle_between_three_points((points_row_norm[temp_torso_points[0]][0], points_row_norm[temp_torso_points[0]][1] - 1), \n",
    "                                                       points_row_norm[temp_torso_points[0]],\n",
    "                                                       points_row_norm[temp_torso_points[1]]\n",
    "                                                      )\n",
    "    \n",
    "    correct_land_posture = False\n",
    "    knee_angle_pass = False\n",
    "    torso_angle_pass = False\n",
    "    land_distance_pass = False\n",
    "    \n",
    "    for i, p in enumerate(temp_leg_points[:-1]):\n",
    "        if knee_angle < 150:\n",
    "            knee_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_leg_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_leg_points[i+1]], (0, 0, 255), thickness=2)\n",
    "            \n",
    "    for i, p in enumerate(temp_torso_points[:-1]):\n",
    "        if torso_angle < 10:\n",
    "            torso_angle_pass = True\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_torso_points[i+1]], (0, 255, 0), thickness=2)\n",
    "        else:\n",
    "            cv2.line(frame_copy, points_row_imputed[p], points_row_imputed[temp_torso_points[i+1]], (0, 0, 255), thickness=2)\n",
    "    \n",
    "    for i in points_row_imputed.index:\n",
    "        if points_row_imputed[i] != None:\n",
    "            if points_row_original[i] != None:\n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "                # cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.circle(frame_copy, points_row_imputed[i], 5, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "                # cv2.putText(frame_copy, f\"{i}\", points_row_imputed[i], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(frame_copy, f\"frame = {frame_counter}\", (10, frame_height-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    land_distance = calculate_distance_from_squat_to_land()\n",
    "    if land_distance <= 1:\n",
    "        land_distance_pass = True\n",
    "    \n",
    "    if knee_angle_pass and torso_angle_pass and land_distance_pass:\n",
    "        correct_land_posture = True\n",
    "    \n",
    "    frame_text = \"\"\n",
    "    if correct_land_posture:\n",
    "        frame_text = \"Landing posture : PASS\"\n",
    "    else:\n",
    "        frame_text = \"Landing posture : FAIL\"\n",
    "    \n",
    "    report_text = f'''\n",
    "    {frame_text} (frame {frame_counter} of {total_frames})\n",
    "    Body angles:\n",
    "    \\tKnee:\\t{round(knee_angle, 2)} deg\\t[correct range: <150 deg]\n",
    "    \\tTorso:\\t{round(torso_angle, 2)} deg\\t[correct range: <10 deg]\n",
    "    \n",
    "    Landing distance: {round(land_distance , 2)} X Upper Body length [correct range: <=1]\n",
    "    '''\n",
    "\n",
    "    return frame_copy, frame_text, report_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_frame_text(frame, squat_frame_text, peak_frame_text, land_frame_text):\n",
    "    \n",
    "    frame_copy = np.copy(frame)\n",
    "    \n",
    "    if \"PASS\" in squat_frame_text:\n",
    "        cv2.putText(frame_copy, squat_frame_text, (10, 75), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, lineType=cv2.LINE_AA)\n",
    "    elif \"FAIL\" in squat_frame_text:\n",
    "        cv2.putText(frame_copy, squat_frame_text, (10, 75), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame_copy, \"Squat posture : ANALYSING...\", (10, 75), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    if \"PASS\" in peak_frame_text:\n",
    "        cv2.putText(frame_copy, peak_frame_text, (10, 125), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, lineType=cv2.LINE_AA)\n",
    "    elif \"FAIL\" in peak_frame_text:\n",
    "        cv2.putText(frame_copy, peak_frame_text, (10, 125), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame_copy, \"Jump Peak posture : ANALYSING...\", (10, 125), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    if \"PASS\" in land_frame_text:\n",
    "        cv2.putText(frame_copy, land_frame_text, (10, 175), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, lineType=cv2.LINE_AA)\n",
    "    elif \"FAIL\" in land_frame_text:\n",
    "        cv2.putText(frame_copy, land_frame_text, (10, 175), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame_copy, \"Landing posture : ANALYSING...\", (10, 175), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3, lineType=cv2.LINE_AA)\n",
    "        \n",
    "    return frame_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the video filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n",
    "\n",
    "def new_final_vid_name(org_vid_path):\n",
    "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
    "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "\n",
    "    new_vid_name_ext = vid_name+\"_ANALYSIS_VIDEO\"+\".mp4\"\n",
    "    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n",
    "\n",
    "    return new_vid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to return the video filepath with a new filename.\n",
    "# If INPUT filepath is \"my_folder1/my_folder2/my_video.mp4\", OUTPUT filepath will be \"my_folder1/my_folder2/my_video_WITH_AGE.mp4\"\n",
    "\n",
    "def new_final_report_name(org_vid_path):\n",
    "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
    "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "\n",
    "    report_name_ext = vid_name+\"_ANALYSIS_REPORT\"+\".txt\"\n",
    "    report_path = os.path.join(vid_path, report_name_ext)\n",
    "\n",
    "    return report_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../inputs_outputs/videos\\vertical_jump_side_trial_1_ANALYSIS_VIDEO.mp4\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# Reading the video from filepath provided above and passing it through the age clasification method defined above.\n",
    "# Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "# Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "# Creating a VideoCapture object.\n",
    "cap = cv2.VideoCapture(my_video)\n",
    "\n",
    "# Checking if video can be accessed successfully.\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read video!\")\n",
    "\n",
    "# Defining the codec and creating a VideoWriter object to save the output video at the same location.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "new_my_video = new_final_vid_name(my_video)\n",
    "out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n",
    "    \n",
    "# Defining a new dataframe to store the skeleton point coordinates from each frame of the video.\n",
    "frame_counter = 1\n",
    "squat_frame_text = \"\"\n",
    "peak_frame_text = \"\"\n",
    "land_frame_text = \"\"\n",
    "\n",
    "final_report_text = f'''VERTICAL JUMP REPORT\n",
    "Video Path : {my_video}\n",
    "'''\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Grabbing each individual frame, frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        if frame_counter == jump_squat_frame:\n",
    "            skeleton_frame, squat_frame_text, report_text = jump_quality_at_squat_frame(frame, df.loc[frame_counter], df_imputed.loc[frame_counter], df_imputed_norm.loc[frame_counter])\n",
    "            final_report_text += report_text\n",
    "            \n",
    "        elif frame_counter == jump_peak_frame:\n",
    "            skeleton_frame, peak_frame_text, report_text = jump_quality_at_peak_frame(frame, df.loc[frame_counter], df_imputed.loc[frame_counter], df_imputed_norm.loc[frame_counter])\n",
    "            final_report_text += report_text\n",
    "            \n",
    "        elif frame_counter == jump_land_frame:\n",
    "            skeleton_frame, land_frame_text, report_text = jump_quality_at_land_frame(frame, df.loc[frame_counter], df_imputed.loc[frame_counter], df_imputed_norm.loc[frame_counter])\n",
    "            final_report_text += report_text\n",
    "            \n",
    "        else:\n",
    "            skeleton_frame = overlay_imputed_skeleton(frame, df_imputed.loc[frame_counter], df.loc[frame_counter], frame_counter)\n",
    "            \n",
    "        skeleton_frame = overlay_frame_text(skeleton_frame, squat_frame_text, peak_frame_text, land_frame_text)\n",
    "        \n",
    "        # Saving frame to output video using the VideoWriter object defined above.\n",
    "        out.write(skeleton_frame)\n",
    "        \n",
    "        # Displaying the frame with age detected.\n",
    "        # cv2.imshow(\"Output Video\", skeleton_frame)\n",
    "        \n",
    "        frame_counter += 1\n",
    "        \n",
    "        # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the VideoCapture and VideoWriter objects, and closing the displayed frame.\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows()\n",
    "print(f\"Analysis video saved at {new_my_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = new_final_report_name(my_video)\n",
    "\n",
    "with open(final_report, \"w\") as text_file:\n",
    "    text_file.write(final_report_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VERTICAL JUMP REPORT\n",
      "Video Path : ../inputs_outputs/videos/vertical_jump_side_trial_1.mp4\n",
      "\n",
      "    Squat posture : PASS (frame 21 of 67)\n",
      "    Body angles:\n",
      "    \tElbow:\t179.77 deg\t[correct range: >160 deg]\n",
      "    \tKnee:\t85.27 deg\t[correct range: 75-105 deg]\n",
      "    \tShldr:\t29.29 deg\n",
      "    \tHip:\t85.27 deg\n",
      "    \n",
      "    Jump Peak posture : FAIL (frame 39 of 67)\n",
      "    Body angles:\n",
      "    \tElbow:\t140.88 deg\t[correct range: >150 deg]\n",
      "    \tKnee:\t152.14 deg\t[correct range: >150 deg]\n",
      "    \tTorso:\t14.04 deg\t[correct range: <20 deg]\n",
      "    \n",
      "    Landing posture : PASS (frame 52 of 67)\n",
      "    Body angles:\n",
      "    \tKnee:\t122.17 deg\t[correct range: <150 deg]\n",
      "    \tTorso:\t3.08 deg\t[correct range: <10 deg]\n",
      "    \n",
      "    Landing distance: 0.11 X Upper Body length [correct range: <=1]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "print(final_report_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def run_program():\n",
    "    \n",
    "    # Source for code: https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n",
    "\n",
    "    # Specify the paths for the 2 files\n",
    "    protoFile = \"../inputs_outputs/models/pose_deploy.prototxt\"\n",
    "    weightsFile = \"../inputs_outputs/models/pose_iter_584000.caffemodel\"\n",
    "\n",
    "    # Read the network into Memory\n",
    "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "    \n",
    "    \n",
    "    # Provide the video filepath as a string below\n",
    "    # For example: \"my_video.mp4\" or \"/content/drive/My Drive/my_folder/my_video.mp4\"\n",
    "\n",
    "    my_video = input(\"Provide the video filepath as a string.\\n\\nINPUT-> \")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    orient = input(\"Is the person in the video facing towards left or right of the video frame?\\n\\nINPUT-> \")\n",
    "    orient = orient.lower()\n",
    "\n",
    "    print(\"\\nPROCESSING... PLEASE WAIT!\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
