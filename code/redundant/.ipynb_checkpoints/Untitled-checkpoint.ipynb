{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_base_normal_length(points_df, start_point, end_point):\n",
    "    \n",
    "    base_normal_length = 0\n",
    "    \n",
    "    for i in points_df.index:\n",
    "        \n",
    "        if ((points_df.loc[i, start_point] != None) and (points_df.loc[i, end_point] != None)):\n",
    "            \n",
    "            start_point_x, start_point_y = points_df.loc[i, start_point]\n",
    "            end_point_x, end_point_y = points_df.loc[i, end_point]\n",
    "            \n",
    "            base_normal_length = int(round(np.sqrt((start_point_x - end_point_x)**2 + (start_point_y - end_point_y)**2)))\n",
    "            \n",
    "            break\n",
    "            \n",
    "    return base_normal_length\n",
    "\n",
    "def normalizing_body_points_in_df(points_df, base_normal_start, base_normal_end, base_normal_mult, origin_point):\n",
    "    \n",
    "    base_normal_length = find_base_normal_length(points_df, base_normal_start, base_normal_end)\n",
    "    \n",
    "    points_norm_df = points_df.copy()\n",
    "    points_norm_df[\"normalized?\"] = \"no\"\n",
    "    points_norm_df[\"origin_point\"] = origin_point\n",
    "\n",
    "    for i in list(points_norm_df.index):\n",
    "        \n",
    "        if points_norm_df.loc[i, origin_point] != None:\n",
    "            points_norm_df.loc[i, \"normalized?\"] = \"yes\"\n",
    "            origin_x, origin_y = points_norm_df.loc[i, origin_point]\n",
    "    \n",
    "            for p in [point for point in points_norm_df.columns if point not in [\"normalized?\", \"origin_point\"]]:\n",
    "                if p == origin_point:\n",
    "                    norm_x = 0.0\n",
    "                    norm_y = 0.0\n",
    "                    points_norm_df.at[i, p] = (norm_x, norm_y)\n",
    "                    \n",
    "                elif points_norm_df.loc[i, p] == None:\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    p_x, p_y = points_norm_df.loc[i, p]\n",
    "                    norm_x = (p_x - origin_x) / (base_normal_length * base_normal_mult)\n",
    "                    norm_y = (p_y - origin_y) / (base_normal_length * base_normal_mult)\n",
    "                    # norm_y = -1 * norm_y\n",
    "                    points_norm_df.at[i, p] = (norm_x, norm_y)\n",
    "            \n",
    "    return points_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class VJump_data():\n",
    "\n",
    "    def __init__(self, video_path):\n",
    "\n",
    "        self.video_path = video_path\n",
    "\n",
    "    def create_frame_path(self, frame_counter):\n",
    "        vid_path, vid_name_ext = os.path.split(self.video_path)\n",
    "        vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "\n",
    "        frame_path = os.path.join(vid_path, vid_name)\n",
    "        \n",
    "        if not os.path.exists(frame_path):\n",
    "            os.makedirs(frame_path)\n",
    "            \n",
    "        frame_path = os.path.join(frame_path, f\"{vid_name}_frame_{frame_counter}.png\")\n",
    "\n",
    "        return frame_path\n",
    "\n",
    "    def count_and_save_frames(self):\n",
    "\n",
    "        # Source 1: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "        # Source 2: https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "\n",
    "        # Creating a VideoCapture object.\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        # Getting the video frame width and height.\n",
    "        self.frame_width = int(cap.get(3))\n",
    "        self.frame_height = int(cap.get(4))\n",
    "        \n",
    "        total_frames = 0\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            # Grabbing each individual frame, frame-by-frame.\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret==True:\n",
    "\n",
    "                total_frames += 1\n",
    "\n",
    "                cv2.imwrite(self.create_frame_path(total_frames), frame)\n",
    "\n",
    "                # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Releasing the VideoCapture object.\n",
    "        cap.release()\n",
    "        \n",
    "        self.total_frames = total_frames\n",
    "\n",
    "    def import_body_net(self):\n",
    "\n",
    "        # Source for code: https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/\n",
    "\n",
    "        # Specify the paths for the 2 files\n",
    "        protoFile = \"../../inputs_outputs/models/pose_deploy.prototxt\"\n",
    "        weightsFile = \"../../inputs_outputs/models/pose_iter_584000.caffemodel\"\n",
    "\n",
    "        # Read the network into Memory\n",
    "        self.net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "    def find_skeleton(self, frame):\n",
    "\n",
    "        frame_copy = np.copy(frame)\n",
    "\n",
    "        # Specify the input image dimensions\n",
    "        inWidth = 368\n",
    "        inHeight = 368\n",
    "\n",
    "        # Prepare the frame to be fed to the network\n",
    "        inpBlob = cv2.dnn.blobFromImage(frame_copy, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "        # Set the prepared object as the input blob of the network\n",
    "        self.net.setInput(inpBlob)\n",
    "\n",
    "        output = self.net.forward()\n",
    "\n",
    "        H = output.shape[2]\n",
    "        W = output.shape[3]\n",
    "\n",
    "        # Empty list to store the detected keypoints\n",
    "        points = []\n",
    "        \n",
    "        for i in range(15):\n",
    "            # Confidence map of corresponding body's part.\n",
    "            probMap = output[0, i, :, :]\n",
    "\n",
    "            # Find global maxima of the probMap.\n",
    "            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "            # Scale the point to fit on the original image\n",
    "            x = (frame_copy.shape[1] * point[0]) / W\n",
    "            y = (frame_copy.shape[0] * point[1]) / H\n",
    "\n",
    "            if prob > 0.5:\n",
    "                # Add the point to the list if the probability is greater than the threshold\n",
    "                points.append((int(x), int(y)))\n",
    "\n",
    "            else:\n",
    "                points.append(None)\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def locate_body_points(self):\n",
    "    \n",
    "        # Creating a VideoCapture object.\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        # Defining a new dataframe to store the skeleton point coordinates from each frame of the video.\n",
    "        df_vid_points = pd.DataFrame()\n",
    "        frame_counter = 1\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            # Grabbing each individual frame, frame-by-frame.\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret==True:\n",
    "\n",
    "                print(f\"Analysing video - frame {frame_counter} of {self.total_frames}...\")\n",
    "                logging.debug(f\"Locating body points - frame {frame_counter} of {self.total_frames}.\")\n",
    "\n",
    "                # Running human skeleton points detection on the grabbed frame.\n",
    "                # if frame_counter < 4:\n",
    "                skeleton_frame_points = self.find_skeleton(frame)\n",
    "\n",
    "                # Saving frame output skeleton point coordinates as a new row in above defined dataframe.\n",
    "                df_vid_points[frame_counter] = skeleton_frame_points\n",
    "                frame_counter += 1\n",
    "\n",
    "                # Exiting if \"Q\" key is pressed on the keyboard.\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Releasing the VideoCapture object.\n",
    "        cap.release()\n",
    "        \n",
    "        df_vid_points = df_vid_points.T.copy()\n",
    "        \n",
    "        self.df_vid_points = df_vid_points\n",
    "        \n",
    "        # self.df_vid_points_norm = self.df_vid_points.copy()\n",
    "\n",
    "    def normalize_body_points(self):\n",
    "\n",
    "        # from VJump import Body_Points_Normalization\n",
    "\n",
    "        self.df_vid_points_norm = normalizing_body_points_in_df(self.df_vid_points, 1, 8, 3, 0)\n",
    "\n",
    "    def separate_x_y_points(self, df):\n",
    "\n",
    "        return_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "        for p in [col for col in df.columns if type(col)==int]:\n",
    "\n",
    "            p_x = []\n",
    "            p_y = []\n",
    "            \n",
    "            for i in df[p]:\n",
    "\n",
    "                if i==None:\n",
    "                    p_x.append(None)\n",
    "                    p_y.append(None)\n",
    "                \n",
    "                else:\n",
    "                    p_x.append(float(i[0]))\n",
    "                    p_y.append(float(i[1]))\n",
    "            \n",
    "            return_df[f\"{p}_x\"] = p_x\n",
    "            return_df[f\"{p}_y\"] = p_y\n",
    "\n",
    "        for p in [col for col in df.columns if type(col)!=int]:\n",
    "            \n",
    "            return_df[p] = df[p]\n",
    "\n",
    "        return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from VJump import VJump_dataset_creation\n",
    "import cv2\n",
    "import time\n",
    "import logging\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# logging.basicConfig(filename=f\"../inputs_outputs/logs/vjump_dataset_creation_log_{timestr}.txt\", filemode='a', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n",
    "# logging.disable(logging.CRITICAL)\n",
    "\n",
    "def run_vjump_dataset_creation():\n",
    "\n",
    "    # logging.debug(f\"----- MAIN PROGRAM STARTED -----\\n\")\n",
    "\n",
    "    video_read_successfully = False\n",
    "    attempt = 1\n",
    "\n",
    "    while video_read_successfully == False and attempt <= 5:\n",
    "        video_path = input(\"Provide the video filepath.\\n\\nINPUT-> \")\n",
    "        logging.debug(f\"Video path given by user: '{video_path}'.\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            # Checking if video can be accessed successfully.\n",
    "            if (cap.isOpened() == False):\n",
    "                print(\"Unable to read video. Re-enter video path.\")\n",
    "                print(f\"Attempts remaining: {5-attempt}\")\n",
    "                logging.debug(f\"Attempt {attempt} - unable to access video.\")\n",
    "                attempt += 1\n",
    "            else:\n",
    "                video_read_successfully = True\n",
    "                logging.debug(f\"Attempt {attempt} - video accessed successfully.\")\n",
    "\n",
    "            # Releasing the VideoCapture object.\n",
    "            cap.release()\n",
    "\n",
    "        except:\n",
    "            print(\"Unable to read video. Re-enter video path.\")\n",
    "            print(f\"Attempts remaining: {5-attempt}\")\n",
    "            logging.exception(f\"EXCEPTION OCCURED - Attempt {attempt} - unable to access video.\")\n",
    "            attempt += 1\n",
    "\n",
    "    if video_read_successfully == False:\n",
    "        print(\"Unable to read video.\")\n",
    "        print(\"Program will exit in 10 seconds.\")\n",
    "        logging.debug(f\"Unable to access video after 5 attempts. Program will be TERMINATED.\")\n",
    "        time.sleep(10)\n",
    "        return\n",
    "    \n",
    "    print(\"\\nPROCESSING... PLEASE WAIT!\\n\")\n",
    "\n",
    "    my_video = VJump_data(video_path)\n",
    "    logging.debug(f\"VJump_data object successfully created.\")\n",
    "\n",
    "    logging.debug(f\"Starting to count total frames and save them.\")\n",
    "    my_video.count_and_save_frames()\n",
    "    print(f\"Total frames in video = {my_video.total_frames}\")\n",
    "    logging.debug(f\"Total frames in video = {my_video.total_frames}\")\n",
    "\n",
    "    try:\n",
    "        logging.debug(f\"Starting to import body net model files.\")\n",
    "        my_video.import_body_net()\n",
    "        logging.debug(f\"Successfully imported body net model files.\")\n",
    "    except:\n",
    "        print(\"Could not find body net model files to find body points in video. Ensure that files pose_deploy.prototxt & pose_iter_584000.caffemodel are stored in ../inputs_outputs/models folder.\\n\")\n",
    "        print(\"Program will exit in 10 seconds.\")\n",
    "        logging.exception(f\"EXCEPTION OCCURED - Unable to access body net model files. Program will be TERMINATED.\")\n",
    "        time.sleep(10)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        logging.debug(f\"Starting to locate body points in video.\")\n",
    "        my_video.locate_body_points()\n",
    "        logging.debug(f\"Successfully located body points in video.\")\n",
    "    except:\n",
    "        print(\"Error while locating body points on video. Please provide a new video.\\n\")\n",
    "        print(\"Program will exit in 10 seconds.\")\n",
    "        logging.exception(f\"EXCEPTION OCCURED - Unable to locate body points in video. Program will be TERMINATED.\")\n",
    "        time.sleep(10)\n",
    "        return\n",
    "    \n",
    "    # return my_video.df_vid_points\n",
    "    \n",
    "    try:\n",
    "        print(\"Normalizing body points...\")\n",
    "        logging.debug(f\"Starting to normalize body points.\")\n",
    "        my_video.normalize_body_points()\n",
    "        print(\"Successfully normalized body points.\\n\")\n",
    "        logging.debug(f\"Successfully normalized body points.\")\n",
    "\n",
    "    except:\n",
    "        print(\"Error while normalizing body points. Please provide a new video.\\n\")\n",
    "        print(\"Program will exit in 10 seconds.\")\n",
    "        logging.exception(f\"EXCEPTION OCCURED - Unable to normalize body points. Program will be TERMINATED.\")\n",
    "        time.sleep(10)\n",
    "        return\n",
    "    \n",
    "    # return my_video.df_vid_points, my_video.df_vid_points_norm\n",
    "    \n",
    "    my_video.df_vid_points = my_video.separate_x_y_points(my_video.df_vid_points)\n",
    "    my_video.df_vid_points_norm = my_video.separate_x_y_points(my_video.df_vid_points_norm)\n",
    "    \n",
    "    return my_video.df_vid_points, my_video.df_vid_points_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df, df_norm = run_vjump_dataset_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame_labels = pd.DataFrame(columns=[\"squat\", \"jump_peak\", \"landing\"], index=range(1, 67+1), data=0)\n",
    "df_frame_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "txt = \"1, 2, 4000, 6, 777 , 10. \"\n",
    "x = re.findall(\"[0-9]+\", txt)\n",
    "\n",
    "for i, frame in enumerate(x):\n",
    "    x[i] = int(frame)\n",
    "\n",
    "x = sorted(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.findall(\"^The.*Spain$\", txt)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "my_video = \"C:\\\\Users\\\\USER\\\\Documents\\\\Python Scripts\\\\wonder_years_fitness_ai\\\\w_yrs_poc1\\\\inputs_outputs\\\\videos\\\\vertical_jump_side_trial_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Documents\\Python Scripts\\wonder_years_fitness_ai\\w_yrs_poc1\\inputs_outputs\\videos\\vertical_jump_side_trial_1\n"
     ]
    }
   ],
   "source": [
    "print(my_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "0\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for root, dirs, files in os.walk(my_video):\n",
    "    print(len(root))\n",
    "    print(len(dirs))\n",
    "    print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(my_video+\".zip\", \"w\") as myzip:\n",
    "    for root, dirs, files in os.walk(my_video):\n",
    "        for file in files:\n",
    "            myzip.write(filename=os.path.join(my_video, file), arcname=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:\\\\Users\\\\USER\\\\Documents\\\\Python Scripts\\\\wonder_years_fitness_ai\\\\w_yrs_poc1\\\\inputs_outputs\\\\videos\\\\vertical_jump_side_trial_1', [], ['vertical_jump_side_trial_1_FEATURES_BODY_POINTS.csv', 'vertical_jump_side_trial_1_FEATURES_BODY_POINTS_NORMALIZED.csv', 'vertical_jump_side_trial_1_FRAME_1.png', 'vertical_jump_side_trial_1_FRAME_10.png', 'vertical_jump_side_trial_1_FRAME_11.png', 'vertical_jump_side_trial_1_FRAME_12.png', 'vertical_jump_side_trial_1_FRAME_13.png', 'vertical_jump_side_trial_1_FRAME_14.png', 'vertical_jump_side_trial_1_FRAME_15.png', 'vertical_jump_side_trial_1_FRAME_16.png', 'vertical_jump_side_trial_1_FRAME_17.png', 'vertical_jump_side_trial_1_FRAME_18.png', 'vertical_jump_side_trial_1_FRAME_19.png', 'vertical_jump_side_trial_1_FRAME_2.png', 'vertical_jump_side_trial_1_FRAME_20.png', 'vertical_jump_side_trial_1_FRAME_21.png', 'vertical_jump_side_trial_1_FRAME_22.png', 'vertical_jump_side_trial_1_FRAME_23.png', 'vertical_jump_side_trial_1_FRAME_24.png', 'vertical_jump_side_trial_1_FRAME_25.png', 'vertical_jump_side_trial_1_FRAME_26.png', 'vertical_jump_side_trial_1_FRAME_27.png', 'vertical_jump_side_trial_1_FRAME_28.png', 'vertical_jump_side_trial_1_FRAME_29.png', 'vertical_jump_side_trial_1_FRAME_3.png', 'vertical_jump_side_trial_1_FRAME_30.png', 'vertical_jump_side_trial_1_FRAME_31.png', 'vertical_jump_side_trial_1_FRAME_32.png', 'vertical_jump_side_trial_1_FRAME_33.png', 'vertical_jump_side_trial_1_FRAME_34.png', 'vertical_jump_side_trial_1_FRAME_35.png', 'vertical_jump_side_trial_1_FRAME_36.png', 'vertical_jump_side_trial_1_FRAME_37.png', 'vertical_jump_side_trial_1_FRAME_38.png', 'vertical_jump_side_trial_1_FRAME_39.png', 'vertical_jump_side_trial_1_FRAME_4.png', 'vertical_jump_side_trial_1_FRAME_40.png', 'vertical_jump_side_trial_1_FRAME_41.png', 'vertical_jump_side_trial_1_FRAME_42.png', 'vertical_jump_side_trial_1_FRAME_43.png', 'vertical_jump_side_trial_1_FRAME_44.png', 'vertical_jump_side_trial_1_FRAME_45.png', 'vertical_jump_side_trial_1_FRAME_46.png', 'vertical_jump_side_trial_1_FRAME_47.png', 'vertical_jump_side_trial_1_FRAME_48.png', 'vertical_jump_side_trial_1_FRAME_49.png', 'vertical_jump_side_trial_1_FRAME_5.png', 'vertical_jump_side_trial_1_FRAME_50.png', 'vertical_jump_side_trial_1_FRAME_51.png', 'vertical_jump_side_trial_1_FRAME_52.png', 'vertical_jump_side_trial_1_FRAME_53.png', 'vertical_jump_side_trial_1_FRAME_54.png', 'vertical_jump_side_trial_1_FRAME_55.png', 'vertical_jump_side_trial_1_FRAME_56.png', 'vertical_jump_side_trial_1_FRAME_57.png', 'vertical_jump_side_trial_1_FRAME_58.png', 'vertical_jump_side_trial_1_FRAME_59.png', 'vertical_jump_side_trial_1_FRAME_6.png', 'vertical_jump_side_trial_1_FRAME_60.png', 'vertical_jump_side_trial_1_FRAME_61.png', 'vertical_jump_side_trial_1_FRAME_62.png', 'vertical_jump_side_trial_1_FRAME_63.png', 'vertical_jump_side_trial_1_FRAME_64.png', 'vertical_jump_side_trial_1_FRAME_65.png', 'vertical_jump_side_trial_1_FRAME_66.png', 'vertical_jump_side_trial_1_FRAME_67.png', 'vertical_jump_side_trial_1_FRAME_7.png', 'vertical_jump_side_trial_1_FRAME_8.png', 'vertical_jump_side_trial_1_FRAME_9.png', 'vertical_jump_side_trial_1_FRAME_LABELS.csv'])\n"
     ]
    }
   ],
   "source": [
    "for files in os.walk(my_video):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'vertical_jump_side_trial_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3727360b8849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"zip\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mroot_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_video\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     \u001b[0mbase_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"vertical_jump_side_trial_1\\\\\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                    )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[1;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_make_zipfile\u001b[1;34m(base_name, base_dir, verbose, dry_run, logger)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m                 \u001b[0mzf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"adding '%s'\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1708\u001b[0m             )\n\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m         \u001b[0mzinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZipInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mzinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, filename, arcname)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[0misdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_ISDIR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mmtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'vertical_jump_side_trial_1'"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(my_video):\n",
    "    for file in files:\n",
    "        ziph.write(os.path.join(root, file))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zipf = zipfile.ZipFile('Python.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "    zipdir('tmp/', zipf)\n",
    "    zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
